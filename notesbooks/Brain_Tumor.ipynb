{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raashidh-Rizvi/Brain-Tumor-Detection/blob/main/Brain_Tumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaWlJz_6qCem",
        "outputId": "0921fedc-08bd-40cd-a93c-556e587e4e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-c87852a9-2ff6-737e-04b5-0c5beab0b4a2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# If you're on Colab, TensorFlow is preinstalled.\n",
        "!nvidia-smi -L  # optional: shows GPU\n",
        "\n",
        "import os, glob, itertools, random, pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "SEED = 1337\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "IMG_SIZE   = 224     # good default for transfer learning\n",
        "BATCH_SIZE = 32\n",
        "VAL_SPLIT  = 0.2   # create a validation set from Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j1Nr7F2cqMF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d277ad3b-e50e-4b7b-8f36-bf564091ec96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# CHANGE THIS to your dataset root in Drive\n",
        "DATA_ROOT = \"/content/drive/MyDrive/BrainTumor\"  # contains Training/ and Testing/\n",
        "\n",
        "TRAIN_DIR = os.path.join(DATA_ROOT, \"Training\")\n",
        "TEST_DIR  = os.path.join(DATA_ROOT, \"Testing\")\n",
        "\n",
        "assert os.path.isdir(TRAIN_DIR) and os.path.isdir(TEST_DIR), \"Check your paths.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XF9s_BZEqgkv"
      },
      "outputs": [],
      "source": [
        "def count_images(root):\n",
        "    data = []\n",
        "    for split in [\"Training\", \"Testing\"]:\n",
        "        split_dir = os.path.join(root, split)\n",
        "        for cls in sorted(os.listdir(split_dir)):\n",
        "            cls_dir = os.path.join(split_dir, cls)\n",
        "            if os.path.isdir(cls_dir):\n",
        "                n = len([p for p in glob.glob(cls_dir + \"/*\") if p.lower().endswith(('.png','.jpg','.jpeg'))])\n",
        "                data.append((split, cls, n))\n",
        "    df = pd.DataFrame(data, columns=[\"split\", \"class\", \"count\"])\n",
        "    return df\n",
        "\n",
        "df_counts = count_images(DATA_ROOT)\n",
        "df_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z93sew7ssuEa"
      },
      "outputs": [],
      "source": [
        "# Bar chart: class distribution\n",
        "for split, g in df_counts.groupby(\"split\"):\n",
        "    plt.figure()\n",
        "    plt.title(f\"Class counts — {split}\")\n",
        "    plt.bar(g[\"class\"], g[\"count\"])\n",
        "    plt.xticks(rotation=15)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAxvPtupszDc"
      },
      "outputs": [],
      "source": [
        "# Peek a few random samples from Training\n",
        "def show_samples(folder, n=12):\n",
        "    paths = []\n",
        "    for cls in sorted(os.listdir(folder)):\n",
        "        p = os.path.join(folder, cls)\n",
        "        if os.path.isdir(p):\n",
        "            paths += [os.path.join(p, f) for f in os.listdir(p) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
        "    random.shuffle(paths)\n",
        "    paths = paths[:n]\n",
        "\n",
        "    cols = 4\n",
        "    rows = int(np.ceil(n/cols))\n",
        "    plt.figure(figsize=(12, 3*rows))\n",
        "    for i, p in enumerate(paths, 1):\n",
        "        img = keras.utils.load_img(p)\n",
        "        plt.subplot(rows, cols, i)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(os.path.basename(os.path.dirname(p)))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples(TRAIN_DIR, n=14)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo-H1DQWtFPr"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def find_corrupt_images(folder):\n",
        "    bad = []\n",
        "    for path in glob.glob(folder + \"/**/*\", recursive=True):\n",
        "        if path.lower().endswith(('.png','.jpg','.jpeg')):\n",
        "            try:\n",
        "                with Image.open(path) as im:\n",
        "                    im.verify()\n",
        "            except Exception:\n",
        "                bad.append(path)\n",
        "    return bad\n",
        "\n",
        "bad_files = find_corrupt_images(DATA_ROOT)\n",
        "len(bad_files), bad_files[:5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv4Nsu4etNzX"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='int',              # pairs with SparseCategoricalCrossentropy\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset='training',\n",
        "    seed=SEED,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    validation_split=VAL_SPLIT,\n",
        "    subset='validation',\n",
        "    seed=SEED,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TEST_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    shuffle=False,                 # keep order for evaluation\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3YJc_V0tPoq"
      },
      "outputs": [],
      "source": [
        "# Performance: cache & prefetch\n",
        "def configure(ds, training=False):\n",
        "    ds = ds.cache()\n",
        "    if training:\n",
        "        ds = ds.shuffle(1000, seed=SEED)\n",
        "    return ds.prefetch(AUTOTUNE)\n",
        "\n",
        "train_ds = configure(train_ds, training=True)\n",
        "val_ds   = configure(val_ds)\n",
        "test_ds  = configure(test_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnTDOW7otTO5"
      },
      "outputs": [],
      "source": [
        "# Extract integer labels from the raw training directory to compute weights\n",
        "train_labels = []\n",
        "for cls_idx, cls in enumerate(class_names):\n",
        "    files = glob.glob(os.path.join(TRAIN_DIR, cls, \"*\"))\n",
        "    train_labels += [cls_idx] * len(files)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.arange(num_classes),\n",
        "    y=np.array(train_labels)\n",
        ")\n",
        "class_weights = {i:w for i, w in enumerate(class_weights)}\n",
        "class_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJZ6jn3ptVe4"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.15),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name=\"augmentation\")\n",
        "\n",
        "# EfficientNet expects [0,255] inputs; we'll scale to [0,1] first\n",
        "rescale = layers.Rescaling(1./255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FZsR0IntXMh"
      },
      "outputs": [],
      "source": [
        "base = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=False,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False  # freeze for warmup\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = rescale(x)\n",
        "x = base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7fg-ZKStZAM"
      },
      "outputs": [],
      "source": [
        "ckpt_path = \"/content/brain_tumor_efficientnet.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        ckpt_path, monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\", patience=6, restore_best_weights=True\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.3, patience=3, verbose=1\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0SUECFgvsy2"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.15),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name=\"augmentation\")\n",
        "\n",
        "# EfficientNet expects [0,255] inputs; we'll scale to [0,1] first\n",
        "rescale = layers.Rescaling(1./255)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS3LOb_dv9n4"
      },
      "outputs": [],
      "source": [
        "base = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=False,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base.trainable = False  # freeze for warmup\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = rescale(x)\n",
        "x = base(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KexrlcAyJpkF"
      },
      "outputs": [],
      "source": [
        "ckpt_path = \"/content/brain_tumor_efficientnet.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        ckpt_path, monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\", patience=6, restore_best_weights=True\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.3, patience=3, verbose=1\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGycxkTSJspK"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTTZpMy2JunP"
      },
      "outputs": [],
      "source": [
        "# Plot learning curves\n",
        "def plot_history(h):\n",
        "    plt.figure()\n",
        "    plt.plot(h.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(h.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "    plt.legend(); plt.title(\"Accuracy\"); plt.xlabel(\"epoch\"); plt.ylabel(\"acc\"); plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(h.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(h.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend(); plt.title(\"Loss\"); plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em7VPCAOJww4"
      },
      "outputs": [],
      "source": [
        "# Unfreeze last ~30% of layers\n",
        "base.trainable = True\n",
        "for layer in base.layers[: int(0.7 * len(base.layers))]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-4),  # smaller LR for fine-tuning\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_ft = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "plot_history(history_ft)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVJpgwqkJyZ2"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVGRb_AzJz1Z"
      },
      "outputs": [],
      "source": [
        "# Predictions → classification report & confusion matrix\n",
        "y_true = np.concatenate([y for _, y in test_ds], axis=0)\n",
        "y_pred_proba = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(num_classes)\n",
        "plt.xticks(tick_marks, class_names, rotation=45)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "th = cm.max() / 2\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > th else \"black\")\n",
        "plt.ylabel('True label'); plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX2IBI_eJ19j"
      },
      "outputs": [],
      "source": [
        "SAVE_DIR = \"/content/drive/MyDrive/brain_tumor_model\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "model.save(os.path.join(SAVE_DIR, \"model.keras\"))  # Keras native format\n",
        "with open(os.path.join(SAVE_DIR, \"classes.txt\"), \"w\") as f:\n",
        "    for c in class_names:\n",
        "        f.write(c + \"\\n\")\n",
        "\n",
        "print(\"Saved to:\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8FkN8NkJ31L"
      },
      "outputs": [],
      "source": [
        "def predict_image(path):\n",
        "  path (\"/content/drive/MyDrive/BrainTumor/OIP (1)\")\n",
        "\n",
        "    img = keras.utils.load_img(path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    x = keras.utils.img_to_array(img)[None, ...]   # shape (1, H, W, 3)\n",
        "    x = x / 255.0\n",
        "    proba = model.predict(x)[0]\n",
        "    idx = np.argmax(proba)\n",
        "    return class_names[idx], dict(zip(class_names, proba.round(4)))\n",
        "\n",
        "# Example:\n",
        "# pred, probs = predict_image(\"/content/drive/MyDrive/some_image.jpg\")\n",
        "# pred, probs\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1WKgjSMdeWkRPTJZ788Ap1_HwKEf-oRI5",
      "authorship_tag": "ABX9TyMvAF9Xc9gDCaNGZnEWq3hV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}